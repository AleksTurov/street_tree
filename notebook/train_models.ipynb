{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/street_tree\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(PROJECT_DIR)\n",
    "sys.path.append(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 10:03:30,829 - src.utils - INFO - Logger is ready\n",
      "2025-03-27 10:03:30,834 - src.utils - INFO - This is a test log message.\n",
      "2025-03-27 10:03:30,835 - src.utils - INFO - PROJECT_DIR: /workspaces/street_tree\n",
      "2025-03-27 10:03:30,835 - src.utils - INFO - PATH_LOGS: /workspaces/street_tree/logs\n",
      "2025-03-27 10:03:30,836 - src.utils - INFO - PATH_DATA: /workspaces/street_tree/data\n",
      "2025-03-27 10:03:30,837 - src.utils - INFO - PATH_RAW: /workspaces/street_tree/data/raw\n",
      "2025-03-27 10:03:30,837 - src.utils - INFO - PATH_PROCESSED: /workspaces/street_tree/data/processed\n",
      "2025-03-27 10:03:30,838 - src.utils - INFO - PATH_MODELS: /workspaces/street_tree/models\n",
      "2025-03-27 10:03:30,839 - src.utils - INFO - PATH_REPORTS: /workspaces/street_tree/reports\n",
      "2025-03-27 10:03:30,840 - src.utils - INFO - PATH_DOCS: /workspaces/street_tree/docs\n",
      "2025-03-27 10:03:30,840 - src.utils - INFO - PATH_SRC: /workspaces/street_tree/src\n",
      "2025-03-27 10:03:30,841 - src.utils - INFO - output_path: /workspaces/street_tree/data/raw/2015-street-tree-census-tree-data.zip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from src.config import PATH_RAW, PATH_PROCESSED, URL, NAME_DATASET, PATH_MODELS, output_path\n",
    "from src.dowload_datafraime import download_file\n",
    "from src.visualization import plot_corr_matrix\n",
    "from src.preprocessing import (df_fillna, split_problems, convert_to_bool, encode_and_save_categorical, \n",
    "                               load_and_encode_categorical, split_and_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_file(URL,PATH_RAW, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 10:03:52,051 - src.utils - INFO - Data successfully saved to: /workspaces/street_tree/data/processed\n",
      "2025-03-27 10:03:52,052 - src.utils - INFO - Train data shape: (586954, 44)\n",
      "2025-03-27 10:03:52,053 - src.utils - INFO - Test data shape: (65218, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(652172, 45)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{PATH_RAW}/{NAME_DATASET}.csv')\n",
    "df = df.dropna(subset=['health'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_and_save(df.drop('health', axis=1), df.health, output_dir=PATH_PROCESSED, size=0.1, name_train='train.csv', name_test='test.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns = [col.lower().replace(' ', '_') for col in X_train.columns]\n",
    "df_drop_columns = ['status', 'state', 'tree_id', 'created_at', 'stump_diam', 'address', 'spc_common',\n",
    "                   'borocode', 'x_sp', 'y_sp', 'council_district', 'census_tract', 'nta_name',\n",
    "                   'bin', 'zip_city', 'community_board', 'bbl']\n",
    "X_train = X_train.drop(columns=df_drop_columns)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/street_tree/src/preprocessing.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['spc_latin'].fillna('No observation',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sidewalk'].fillna('NoDamage',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['problems'].fillna('NoProblem',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['steward'].fillna('None',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['guards'].fillna('Unsure',inplace=True)\n",
      "2025-03-27 10:03:54,692 - src.utils - INFO - Пропуски заполнены\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_fillna(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 10:03:55,459 - src.utils - INFO - {'metalgrates', 'sneakers', 'rootother', 'stones', 'branchlights', 'trunkother', 'noproblem', 'branchother', 'wiresrope', 'trunklights'} - уникальные проблемы\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = split_problems(X_train, created_columns=False)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 10:03:57,771 - src.utils - INFO - Значения преобразованы в булевые\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = convert_to_bool(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spc_latin', 'steward', 'guards', 'user_type', 'borough', 'nta']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = X_train.select_dtypes(include='object').columns.tolist()\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, label_encoders = encode_and_save_categorical(X_train, categorical_columns, PATH_MODELS, 'label_encoders.pkl')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             spc_latin  Code\n",
      "0                 Acer     0\n",
      "1    Acer buergerianum     1\n",
      "2       Acer campestre     2\n",
      "3         Acer ginnala     3\n",
      "4         Acer griseum     4\n",
      "..                 ...   ...\n",
      "128   Tsuga canadensis   128\n",
      "129    Ulmus americana   129\n",
      "130   Ulmus parvifolia   130\n",
      "131       Ulmus pumila   131\n",
      "132    Zelkova serrata   132\n",
      "\n",
      "[133 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Вывод значений, закодированных энкодером для столбца 'health', вместе с соответствующими им числовыми кодами\n",
    "health_classes = label_encoders['spc_latin'].classes_\n",
    "health_codes = label_encoders['spc_latin'].transform(health_classes)\n",
    "\n",
    "# Создание DataFrame для удобного отображения\n",
    "health_mapping = pd.DataFrame({'spc_latin': health_classes, 'Code': health_codes})\n",
    "print(health_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 10:04:03,984 - src.utils - INFO - Data successfully saved to: /workspaces/street_tree/data/processed\n",
      "2025-03-27 10:04:03,985 - src.utils - INFO - Train data shape: (469563, 27)\n",
      "2025-03-27 10:04:03,987 - src.utils - INFO - Test data shape: (117391, 27)\n"
     ]
    }
   ],
   "source": [
    "# Разделим X_train на обучающую и валидационную выборки и y_train на соответствующие им значения\n",
    "X_train, X_val, y_train, y_val = split_and_save(X_train, y_train, output_dir=PATH_PROCESSED, size=0.2, name_train='train.csv', name_test='valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Poor', 'Good', 'Fair'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label encoder saved to label_encoders_target.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the mapping\n",
    "target_mapping = {'Poor': 0, 'Fair': 1, 'Good': 2}\n",
    "\n",
    "y_train = y_train.map(target_mapping)\n",
    "y_val = y_val.map(target_mapping)\n",
    "\n",
    "# Save the mapping to a file\n",
    "joblib.dump(target_mapping, f'{PATH_MODELS}/label_encoders_target.pkl')\n",
    "\n",
    "print(\"Target label encoder saved to label_encoders_target.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, f'{PATH_MODELS}/scaler.pkl')\n",
    "print(\"Scaler saved to scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469563, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 10:04:07,139 - src.utils - INFO - Unique classes during training: [0 1 2]\n",
      "2025-03-27 10:04:07,140 - src.utils - INFO - Output dimension during training: 3\n",
      "2025-03-27 10:04:21,467 - src.utils - INFO - Epoch 1/2 - Train Loss: 7709.1301, Val Loss: 1896.6871, LR: 0.001000\n",
      "2025-03-27 10:04:21,468 - src.utils - INFO - Accuracy: 0.5596, F1-Score: 0.6268, AUC-ROC: 0.6522\n",
      "2025-03-27 10:04:21,469 - src.utils - INFO - Confusion Matrix:\n",
      "2470\t884\t1473\n",
      "6085\t3975\t7311\n",
      "21839\t14106\t59248\n",
      "2025-03-27 10:04:21,471 - src.utils - INFO - Best model saved based on highest AUC-ROC.\n",
      "2025-03-27 10:04:34,398 - src.utils - INFO - Epoch 2/2 - Train Loss: 7614.1400, Val Loss: 1888.6606, LR: 0.001000\n",
      "2025-03-27 10:04:34,399 - src.utils - INFO - Accuracy: 0.6180, F1-Score: 0.6667, AUC-ROC: 0.6552\n",
      "2025-03-27 10:04:34,400 - src.utils - INFO - Confusion Matrix:\n",
      "2115\t974\t1738\n",
      "5011\t3965\t8395\n",
      "15338\t13393\t66462\n",
      "2025-03-27 10:04:34,402 - src.utils - INFO - Best model saved based on highest AUC-ROC.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.modeling import TabularNN\n",
    "\n",
    "# Instantiate the model\n",
    "model = TabularNN(X_train, y_train, X_val, y_val, hidden_dims=[128, 64], model_path=f'{PATH_MODELS}/tabular_model.pth')\n",
    "\n",
    "# Train the model\n",
    "model.train_model(epochs=2, learning_rate=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8482/2322857789.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_PATH)\n",
      "2025-03-27 10:04:34,453 - src.utils - INFO - Unique classes during training: [0 1 2]\n",
      "2025-03-27 10:04:34,454 - src.utils - INFO - Output dimension during training: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabularNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=27, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.modeling import TabularNN\n",
    "from src.config import PATH_MODELS\n",
    "import torch\n",
    "\n",
    "# Define the path to the saved model\n",
    "MODEL_PATH = f\"{PATH_MODELS}/tabular_model.pth\"\n",
    "\n",
    "# Load the checkpoint to get the parameters\n",
    "checkpoint = torch.load(MODEL_PATH)\n",
    "input_dim = checkpoint['input_dim']\n",
    "hidden_dims = checkpoint['hidden_dims']\n",
    "output_dim = checkpoint['output_dim']\n",
    "target_mapping = checkpoint['target_mapping']\n",
    "\n",
    "# Create dummy data with the correct shape\n",
    "dummy_X = pd.DataFrame(np.zeros((3, input_dim)))\n",
    "dummy_y = pd.Series([0, 1, 2]) \n",
    "\n",
    "# Initialize the model using dummy data\n",
    "loaded_model = TabularNN(dummy_X, dummy_y, dummy_X, dummy_y, hidden_dims=hidden_dims)\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Получим предсказания для dummy_X\n",
    "loaded_model.predict(dummy_X)\n",
    "\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_catboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostModelTrain\n\u001b[1;32m      5\u001b[0m catboost_model \u001b[38;5;241m=\u001b[39m CatBoostModelTrain(model_dir\u001b[38;5;241m=\u001b[39mPATH_MODELS)\n\u001b[1;32m      6\u001b[0m catboost_model\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train, X_val, y_val)\n",
      "File \u001b[0;32m/workspaces/street_tree/src/modeling_catboost.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score, roc_auc_score, confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.modeling_catboost import CatBoostModelTrain\n",
    "\n",
    "catboost_model = CatBoostModelTrain(model_dir=PATH_MODELS)\n",
    "catboost_model.train(X_train, y_train, X_val, y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
