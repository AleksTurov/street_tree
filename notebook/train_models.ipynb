{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/street_tree\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(PROJECT_DIR)\n",
    "sys.path.append(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:10:57,989 - src.utils - INFO - Logger is ready\n",
      "2025-03-23 14:10:57,990 - src.utils - INFO - This is a test log message.\n",
      "2025-03-23 14:10:57,991 - src.utils - INFO - PROJECT_DIR: /workspaces/street_tree\n",
      "2025-03-23 14:10:57,992 - src.utils - INFO - PATH_LOGS: /workspaces/street_tree/logs\n",
      "2025-03-23 14:10:57,992 - src.utils - INFO - PATH_DATA: /workspaces/street_tree/data\n",
      "2025-03-23 14:10:57,993 - src.utils - INFO - PATH_RAW: /workspaces/street_tree/data/raw\n",
      "2025-03-23 14:10:57,993 - src.utils - INFO - PATH_PROCESSED: /workspaces/street_tree/data/processed\n",
      "2025-03-23 14:10:57,994 - src.utils - INFO - PATH_MODELS: /workspaces/street_tree/models\n",
      "2025-03-23 14:10:57,995 - src.utils - INFO - PATH_REPORTS: /workspaces/street_tree/reports\n",
      "2025-03-23 14:10:57,995 - src.utils - INFO - PATH_DOCS: /workspaces/street_tree/docs\n",
      "2025-03-23 14:10:57,996 - src.utils - INFO - PATH_SRC: /workspaces/street_tree/src\n",
      "2025-03-23 14:10:57,996 - src.utils - INFO - output_path: /workspaces/street_tree/data/raw/2015-street-tree-census-tree-data.zip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from src.config import PATH_RAW, PATH_PROCESSED, URL, NAME_DATASET, PATH_MODELS, output_path\n",
    "from src.dowload_datafraime import download_file\n",
    "from src.visualization import plot_corr_matrix\n",
    "from src.preprocessing import (df_fillna, split_problems, convert_to_bool, encode_and_save_categorical, \n",
    "                               load_and_encode_categorical, split_and_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_file(URL,PATH_RAW, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:11:18,110 - src.utils - INFO - Data successfully saved to: /workspaces/street_tree/data/processed\n",
      "2025-03-23 14:11:18,111 - src.utils - INFO - Train data shape: (586954, 44)\n",
      "2025-03-23 14:11:18,112 - src.utils - INFO - Test data shape: (65218, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(652172, 45)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{PATH_RAW}/{NAME_DATASET}.csv')\n",
    "df = df.dropna(subset=['health'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_and_save(df.drop('health', axis=1), df.health, output_dir=PATH_PROCESSED, size=0.1, name_train='train.csv', name_test='test.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns = [col.lower().replace(' ', '_') for col in X_train.columns]\n",
    "df_drop_columns = ['status', 'state', 'tree_id', 'created_at', 'stump_diam', 'address', 'spc_common',\n",
    "                   'borocode', 'x_sp', 'y_sp', 'council_district', 'census_tract', 'nta_name',\n",
    "                   'bin', 'zip_city', 'community_board', 'bbl']\n",
    "X_train = X_train.drop(columns=df_drop_columns)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/street_tree/src/preprocessing.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['spc_latin'].fillna('No observation',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sidewalk'].fillna('NoDamage',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['problems'].fillna('NoProblem',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['steward'].fillna('None',inplace=True)\n",
      "/workspaces/street_tree/src/preprocessing.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['guards'].fillna('Unsure',inplace=True)\n",
      "2025-03-23 14:11:18,709 - src.utils - INFO - Пропуски заполнены\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_fillna(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:11:19,718 - src.utils - INFO - {'stones', 'noproblem', 'branchother', 'rootother', 'sneakers', 'trunklights', 'branchlights', 'wiresrope', 'trunkother', 'metalgrates'} - уникальные проблемы\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = split_problems(X_train, created_columns=False)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:11:22,045 - src.utils - INFO - Значения преобразованы в булевые\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = convert_to_bool(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spc_latin', 'steward', 'guards', 'user_type', 'borough', 'nta']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = X_train.select_dtypes(include='object').columns.tolist()\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586954, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, label_encoders = encode_and_save_categorical(X_train, categorical_columns, PATH_MODELS, 'label_encoders.pkl')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             spc_latin  Code\n",
      "0                 Acer     0\n",
      "1    Acer buergerianum     1\n",
      "2       Acer campestre     2\n",
      "3         Acer ginnala     3\n",
      "4         Acer griseum     4\n",
      "..                 ...   ...\n",
      "128   Tsuga canadensis   128\n",
      "129    Ulmus americana   129\n",
      "130   Ulmus parvifolia   130\n",
      "131       Ulmus pumila   131\n",
      "132    Zelkova serrata   132\n",
      "\n",
      "[133 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Вывод значений, закодированных энкодером для столбца 'health', вместе с соответствующими им числовыми кодами\n",
    "health_classes = label_encoders['spc_latin'].classes_\n",
    "health_codes = label_encoders['spc_latin'].transform(health_classes)\n",
    "\n",
    "# Создание DataFrame для удобного отображения\n",
    "health_mapping = pd.DataFrame({'spc_latin': health_classes, 'Code': health_codes})\n",
    "print(health_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:11:28,923 - src.utils - INFO - Data successfully saved to: /workspaces/street_tree/data/processed\n",
      "2025-03-23 14:11:28,924 - src.utils - INFO - Train data shape: (469563, 27)\n",
      "2025-03-23 14:11:28,925 - src.utils - INFO - Test data shape: (117391, 27)\n"
     ]
    }
   ],
   "source": [
    "# Разделим X_train на обучающую и валидационную выборки и y_train на соответствующие им значения\n",
    "X_train, X_val, y_train, y_val = split_and_save(X_train, y_train, output_dir=PATH_PROCESSED, size=0.2, name_train='train.csv', name_test='valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Poor', 'Good', 'Fair'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label encoder saved to label_encoders_target.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the mapping\n",
    "target_mapping = {'Poor': 0, 'Fair': 1, 'Good': 2}\n",
    "\n",
    "y_train = y_train.map(target_mapping)\n",
    "y_val = y_val.map(target_mapping)\n",
    "\n",
    "# Save the mapping to a file\n",
    "joblib.dump(target_mapping, f'{PATH_MODELS}/label_encoders_target.pkl')\n",
    "\n",
    "print(\"Target label encoder saved to label_encoders_target.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, f'{PATH_MODELS}/scaler.pkl')\n",
    "print(\"Scaler saved to scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469563, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:11:33,772 - src.utils - INFO - Unique classes during training: [0 1 2]\n",
      "2025-03-23 14:11:33,773 - src.utils - INFO - Output dimension during training: 3\n",
      "2025-03-23 14:11:51,118 - src.utils - INFO - Epoch 1/2 - Train Loss: 7704.4732, Val Loss: 1896.5042, LR: 0.001000\n",
      "2025-03-23 14:11:51,119 - src.utils - INFO - Accuracy: 0.5885, F1-Score: 0.6467, AUC-ROC: 0.6538\n",
      "2025-03-23 14:11:51,120 - src.utils - INFO - Confusion Matrix:\n",
      "2268\t967\t1592\n",
      "5427\t3949\t7995\n",
      "18593\t13727\t62873\n",
      "2025-03-23 14:11:51,123 - src.utils - INFO - Best model saved based on highest AUC-ROC.\n",
      "2025-03-23 14:12:05,202 - src.utils - INFO - Epoch 2/2 - Train Loss: 7614.9514, Val Loss: 1885.3782, LR: 0.001000\n",
      "2025-03-23 14:12:05,202 - src.utils - INFO - Accuracy: 0.5956, F1-Score: 0.6515, AUC-ROC: 0.6680\n",
      "2025-03-23 14:12:05,203 - src.utils - INFO - Confusion Matrix:\n",
      "2165\t1062\t1600\n",
      "5123\t4525\t7723\n",
      "15139\t16831\t63223\n",
      "2025-03-23 14:12:05,206 - src.utils - INFO - Best model saved based on highest AUC-ROC.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.modeling import TabularNN\n",
    "\n",
    "# Instantiate the model\n",
    "model = TabularNN(X_train, y_train, X_val, y_val, hidden_dims=[128, 64], model_path=f'{PATH_MODELS}/tabular_model.pth')\n",
    "\n",
    "# Train the model\n",
    "model.train_model(epochs=2, learning_rate=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:12:05,267 - src.utils - INFO - Unique classes during training: [0 1 2]\n",
      "2025-03-23 14:12:05,269 - src.utils - INFO - Output dimension during training: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabularNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=27, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.modeling import TabularNN\n",
    "from src.config import PATH_MODELS\n",
    "import torch\n",
    "\n",
    "# Define the path to the saved model\n",
    "MODEL_PATH = f\"{PATH_MODELS}/tabular_model.pth\"\n",
    "\n",
    "# Load the checkpoint to get the parameters\n",
    "checkpoint = torch.load(MODEL_PATH)\n",
    "input_dim = checkpoint['input_dim']\n",
    "hidden_dims = checkpoint['hidden_dims']\n",
    "output_dim = checkpoint['output_dim']\n",
    "target_mapping = checkpoint['target_mapping']\n",
    "\n",
    "# Create dummy data with the correct shape\n",
    "dummy_X = pd.DataFrame(np.zeros((3, input_dim)))\n",
    "dummy_y = pd.Series([0, 1, 2]) \n",
    "\n",
    "# Initialize the model using dummy data\n",
    "loaded_model = TabularNN(dummy_X, dummy_y, dummy_X, dummy_y, hidden_dims=hidden_dims)\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Получим предсказания для dummy_X\n",
    "loaded_model.predict(dummy_X)\n",
    "\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0665870\ttest: 1.0666001\tbest: 1.0666001 (0)\ttotal: 372ms\tremaining: 6m 11s\n",
      "100:\tlearn: 0.5502277\ttest: 0.5516981\tbest: 0.5516981 (100)\ttotal: 47.5s\tremaining: 7m 2s\n",
      "200:\tlearn: 0.5351898\ttest: 0.5379727\tbest: 0.5379727 (200)\ttotal: 1m 21s\tremaining: 5m 23s\n",
      "300:\tlearn: 0.5281540\ttest: 0.5319916\tbest: 0.5319916 (300)\ttotal: 2m 24s\tremaining: 5m 36s\n",
      "400:\tlearn: 0.5230962\ttest: 0.5280030\tbest: 0.5280030 (400)\ttotal: 3m 26s\tremaining: 5m 8s\n",
      "500:\tlearn: 0.5185345\ttest: 0.5245093\tbest: 0.5245093 (500)\ttotal: 4m 6s\tremaining: 4m 5s\n",
      "600:\tlearn: 0.5147071\ttest: 0.5216839\tbest: 0.5216839 (600)\ttotal: 5m 18s\tremaining: 3m 31s\n",
      "700:\tlearn: 0.5113475\ttest: 0.5193132\tbest: 0.5193132 (700)\ttotal: 6m 6s\tremaining: 2m 36s\n",
      "800:\tlearn: 0.5084351\ttest: 0.5173442\tbest: 0.5173442 (800)\ttotal: 6m 53s\tremaining: 1m 42s\n",
      "900:\tlearn: 0.5057840\ttest: 0.5156805\tbest: 0.5156805 (900)\ttotal: 7m 34s\tremaining: 49.9s\n",
      "999:\tlearn: 0.5035322\ttest: 0.5143287\tbest: 0.5143287 (999)\ttotal: 8m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5143287016\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:20:16,150 - src.utils - INFO - Сохраняем модель в /workspaces/street_tree/models/catboost_model.cbm\n",
      "2025-03-23 14:20:16,939 - src.utils - INFO - CatBoost Accuracy: 0.8163, F1-Score: 0.7479, AUC-ROC: 0.7500\n",
      "2025-03-23 14:20:16,940 - src.utils - INFO - Confusion Matrix:\n",
      "[[  197   392  4238]\n",
      " [  102   976 16293]\n",
      " [   37   500 94656]]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.modeling_catboost import CatBoostModelTrain\n",
    "\n",
    "catboost_model = CatBoostModelTrain(model_dir=PATH_MODELS)\n",
    "catboost_model.train(X_train, y_train, X_val, y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
